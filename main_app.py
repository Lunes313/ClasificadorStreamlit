"""
Clasificador IRIS - AplicaciÃ³n Streamlit
Clasificador dinÃ¡mico y pedagÃ³gico para el dataset IRIS con visualizaciones
de desempeÃ±o e interfaz de predicciÃ³n.
"""

import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score,
    confusion_matrix,
    classification_report,
    roc_curve,
    auc,
)
from sklearn.preprocessing import label_binarize

from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ConfiguraciÃ³n de pÃ¡gina
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="Clasificador IRIS",
    page_icon="ğŸŒ¸",
    layout="wide",
    initial_sidebar_state="expanded",
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DescripciÃ³n pedagÃ³gica de cada clasificador
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DESCRIPCIONES = {
    "K-Vecinos MÃ¡s Cercanos (KNN)": (
        "**K-Nearest Neighbors** clasifica cada punto nuevo segÃºn las *k* muestras de "
        "entrenamiento mÃ¡s cercanas. Es un algoritmo **no paramÃ©trico** y **lazy** "
        "(no construye un modelo explÃ­cito). La distancia Euclidiana es la mÃ©trica mÃ¡s comÃºn. "
        "Aumentar *k* reduce el sobreajuste pero puede incrementar el sesgo."
    ),
    "Ãrbol de DecisiÃ³n": (
        "Un **Ãrbol de DecisiÃ³n** divide el espacio de caracterÃ­sticas con reglas "
        "if/else que maximizan la pureza de los nodos (Gini o EntropÃ­a). Es muy "
        "interpretable y puede sobreajustarse si se deja crecer sin lÃ­mites. "
        "La *profundidad mÃ¡xima* controla la complejidad del modelo."
    ),
    "Bosque Aleatorio": (
        "**Random Forest** construye mÃºltiples Ã¡rboles de decisiÃ³n sobre submuestras "
        "aleatorias del dataset y promedia sus predicciones (**bagging**). Reduce el "
        "sobreajuste de los Ã¡rboles individuales y es robusto ante ruido. "
        "El nÃºmero de estimadores y la profundidad mÃ¡xima son los hiperparÃ¡metros clave."
    ),
    "MÃ¡quina de Soporte Vectorial (SVM)": (
        "Una **SVM** busca el hiperplano de mÃ¡ximo margen que separa las clases. "
        "Con el *kernel RBF* puede capturar fronteras no lineales proyectando los datos "
        "a un espacio de mayor dimensiÃ³n. El parÃ¡metro *C* regula el trade-off entre "
        "margen amplio y errores de clasificaciÃ³n."
    ),
    "RegresiÃ³n LogÃ­stica": (
        "La **RegresiÃ³n LogÃ­stica** modela la probabilidad de pertenencia a cada clase "
        "mediante una funciÃ³n sigmoide o softmax (multiclase). Es un clasificador lineal "
        "rÃ¡pido e interpretable. El parÃ¡metro *C* controla la regularizaciÃ³n (mayor C = "
        "menos regularizaciÃ³n)."
    ),
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Carga del dataset
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data
def cargar_datos():
    iris = load_iris()
    df = pd.DataFrame(iris.data, columns=iris.feature_names)
    df["especie"] = pd.Categorical.from_codes(iris.target, iris.target_names)
    return df, iris


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ConstrucciÃ³n del clasificador segÃºn selecciÃ³n
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def crear_clasificador(nombre, params):
    if nombre == "K-Vecinos MÃ¡s Cercanos (KNN)":
        return KNeighborsClassifier(n_neighbors=params["k"])
    if nombre == "Ãrbol de DecisiÃ³n":
        return DecisionTreeClassifier(
            max_depth=params["max_depth"] if params["max_depth"] > 0 else None,
            criterion=params["criterion"],
            random_state=42,
        )
    if nombre == "Bosque Aleatorio":
        return RandomForestClassifier(
            n_estimators=params["n_estimators"],
            max_depth=params["max_depth"] if params["max_depth"] > 0 else None,
            random_state=42,
        )
    if nombre == "MÃ¡quina de Soporte Vectorial (SVM)":
        return SVC(C=params["C"], kernel="rbf", probability=True, random_state=42)
    # RegresiÃ³n LogÃ­stica
    return LogisticRegression(C=params["C"], max_iter=5000, random_state=42)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GrÃ¡fica de distribuciÃ³n por especie
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def graf_distribucion(df):
    fig = px.histogram(
        df,
        x="especie",
        color="especie",
        title="DistribuciÃ³n de muestras por especie",
        labels={"especie": "Especie", "count": "Cantidad"},
        color_discrete_sequence=px.colors.qualitative.Set2,
    )
    fig.update_layout(showlegend=False)
    return fig


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GrÃ¡fica de pares (scatter matrix)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def graf_pares(df):
    fig = px.scatter_matrix(
        df,
        dimensions=df.columns[:4],
        color="especie",
        title="Matriz de dispersiÃ³n de caracterÃ­sticas",
        color_discrete_sequence=px.colors.qualitative.Set2,
    )
    fig.update_traces(diagonal_visible=False, marker=dict(size=4))
    return fig


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GrÃ¡fica de correlaciÃ³n (heatmap)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def graf_correlacion(df):
    corr = df.iloc[:, :4].corr()
    fig = px.imshow(
        corr,
        text_auto=".2f",
        color_continuous_scale="RdBu_r",
        title="Mapa de correlaciÃ³n entre caracterÃ­sticas",
        aspect="auto",
    )
    return fig


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Matriz de confusiÃ³n
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def graf_confusion(y_test, y_pred, clases):
    cm = confusion_matrix(y_test, y_pred)
    fig = px.imshow(
        cm,
        x=clases,
        y=clases,
        text_auto=True,
        color_continuous_scale="Blues",
        title="Matriz de ConfusiÃ³n",
        labels=dict(x="PredicciÃ³n", y="Real", color="Cantidad"),
    )
    fig.update_layout(xaxis_title="PredicciÃ³n", yaxis_title="Real")
    return fig


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Curvas ROC multiclase (One-vs-Rest)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def graf_roc(modelo, X_test, y_test, clases):
    y_bin = label_binarize(y_test, classes=list(range(len(clases))))
    try:
        y_score = modelo.predict_proba(X_test)
    except AttributeError:
        return None

    fig = go.Figure()
    colors = ["#1f77b4", "#ff7f0e", "#2ca02c"]
    for i, cls in enumerate(clases):
        fpr, tpr, _ = roc_curve(y_bin[:, i], y_score[:, i])
        roc_auc = auc(fpr, tpr)
        fig.add_trace(
            go.Scatter(
                x=fpr,
                y=tpr,
                mode="lines",
                name=f"{cls} (AUC = {roc_auc:.2f})",
                line=dict(color=colors[i]),
            )
        )
    fig.add_trace(
        go.Scatter(
            x=[0, 1],
            y=[0, 1],
            mode="lines",
            name="Azar",
            line=dict(color="gray", dash="dash"),
        )
    )
    fig.update_layout(
        title="Curvas ROC (One-vs-Rest)",
        xaxis_title="Tasa de Falsos Positivos",
        yaxis_title="Tasa de Verdaderos Positivos",
        legend_title="Clase",
    )
    return fig


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Importancia de caracterÃ­sticas (si aplica)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def graf_importancia(modelo, feature_names, nombre_clf):
    importancias = None
    if hasattr(modelo, "feature_importances_"):
        importancias = modelo.feature_importances_
    elif hasattr(modelo, "coef_"):
        importancias = np.abs(modelo.coef_).mean(axis=0)

    if importancias is None:
        return None

    df_imp = pd.DataFrame(
        {"CaracterÃ­stica": feature_names, "Importancia": importancias}
    ).sort_values("Importancia", ascending=True)

    fig = px.bar(
        df_imp,
        x="Importancia",
        y="CaracterÃ­stica",
        orientation="h",
        title=f"Importancia de caracterÃ­sticas â€” {nombre_clf}",
        color="Importancia",
        color_continuous_scale="Viridis",
    )
    fig.update_layout(coloraxis_showscale=False)
    return fig


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ValidaciÃ³n cruzada
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def graf_cv(scores):
    fig = go.Figure()
    fig.add_trace(
        go.Bar(
            x=[f"Fold {i+1}" for i in range(len(scores))],
            y=scores,
            marker_color="steelblue",
            text=[f"{s:.3f}" for s in scores],
            textposition="outside",
        )
    )
    fig.add_hline(
        y=scores.mean(),
        line_dash="dash",
        line_color="red",
        annotation_text=f"Media: {scores.mean():.3f}",
    )
    fig.update_layout(
        title="ValidaciÃ³n Cruzada (5-Fold)",
        xaxis_title="Fold",
        yaxis_title="Exactitud",
        yaxis=dict(range=[0, 1.05]),
    )
    return fig


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                  APP PRINCIPAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def main():
    st.title("ğŸŒ¸ Clasificador IRIS â€” Streamlit")
    st.markdown(
        "AplicaciÃ³n **pedagÃ³gica e interactiva** para explorar algoritmos de "
        "clasificaciÃ³n sobre el clÃ¡sico dataset *Iris* de Fisher (1936)."
    )

    df, iris = cargar_datos()
    feature_names = iris.feature_names
    target_names = list(iris.target_names)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Barra lateral
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with st.sidebar:
        st.header("âš™ï¸ ConfiguraciÃ³n")

        clasificador_nombre = st.selectbox(
            "Algoritmo de clasificaciÃ³n",
            list(DESCRIPCIONES.keys()),
        )

        st.subheader("HiperparÃ¡metros")
        params = {}
        if clasificador_nombre == "K-Vecinos MÃ¡s Cercanos (KNN)":
            params["k"] = st.slider("NÃºmero de vecinos (k)", 1, 20, 5)
        elif clasificador_nombre == "Ãrbol de DecisiÃ³n":
            params["max_depth"] = st.slider(
                "Profundidad mÃ¡xima (0 = sin lÃ­mite)", 0, 15, 4
            )
            params["criterion"] = st.selectbox("Criterio", ["gini", "entropy"])
        elif clasificador_nombre == "Bosque Aleatorio":
            params["n_estimators"] = st.slider("NÃºmero de Ã¡rboles", 10, 300, 100)
            params["max_depth"] = st.slider(
                "Profundidad mÃ¡xima (0 = sin lÃ­mite)", 0, 15, 0
            )
        elif clasificador_nombre in (
            "MÃ¡quina de Soporte Vectorial (SVM)",
            "RegresiÃ³n LogÃ­stica",
        ):
            params["C"] = st.slider("ParÃ¡metro C (regularizaciÃ³n)", 0.01, 10.0, 1.0)

        st.subheader("ParticiÃ³n de datos")
        test_size = st.slider("TamaÃ±o del conjunto de prueba (%)", 10, 40, 20) / 100
        escalar = st.checkbox("Escalar caracterÃ­sticas (StandardScaler)", value=True)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PestaÃ±as
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    tab_datos, tab_modelo, tab_prediccion = st.tabs(
        ["ğŸ“Š ExploraciÃ³n de Datos", "ğŸ¤– Modelo y DesempeÃ±o", "ğŸ”® PredicciÃ³n"]
    )

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PESTAÃ‘A 1: DATOS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with tab_datos:
        st.header("Dataset IRIS")
        col1, col2, col3 = st.columns(3)
        col1.metric("Muestras totales", len(df))
        col2.metric("CaracterÃ­sticas", len(feature_names))
        col3.metric("Clases", len(target_names))

        with st.expander("ğŸ“‹ Ver primeras filas del dataset"):
            st.dataframe(df.head(10), use_container_width=True)

        with st.expander("ğŸ“ˆ EstadÃ­sticas descriptivas"):
            st.dataframe(df.describe(), use_container_width=True)

        st.subheader("Visualizaciones exploratorias")
        c1, c2 = st.columns(2)
        with c1:
            st.plotly_chart(graf_distribucion(df), use_container_width=True)
        with c2:
            st.plotly_chart(graf_correlacion(df), use_container_width=True)

        st.plotly_chart(graf_pares(df), use_container_width=True)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PESTAÃ‘A 2: MODELO
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with tab_modelo:
        st.header(f"Algoritmo: {clasificador_nombre}")

        # ExplicaciÃ³n pedagÃ³gica
        with st.expander("ğŸ“š Â¿CÃ³mo funciona este algoritmo?", expanded=True):
            st.markdown(DESCRIPCIONES[clasificador_nombre])

        # Entrenamiento
        X = df[feature_names].values
        y = iris.target

        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=y
        )

        if escalar:
            scaler = StandardScaler()
            X_train = scaler.fit_transform(X_train)
            X_test = scaler.transform(X_test)

        modelo = crear_clasificador(clasificador_nombre, params)
        modelo.fit(X_train, y_train)
        y_pred = modelo.predict(X_test)

        acc_train = accuracy_score(y_train, modelo.predict(X_train))
        acc_test = accuracy_score(y_test, y_pred)

        # MÃ©tricas principales
        st.subheader("ğŸ“ MÃ©tricas de DesempeÃ±o")
        m1, m2, m3 = st.columns(3)
        m1.metric("Exactitud en entrenamiento", f"{acc_train:.2%}")
        m2.metric("Exactitud en prueba", f"{acc_test:.2%}")
        delta = acc_test - acc_train
        m3.metric(
            "Diferencia (sobreajuste)",
            f"{delta:.2%}",
            delta=f"{delta:.2%}",
            delta_color="inverse",
        )

        # ValidaciÃ³n cruzada
        st.subheader("ğŸ”„ ValidaciÃ³n Cruzada (5-Fold)")
        clf_cv = crear_clasificador(clasificador_nombre, params)
        if escalar:
            cv_pipeline = Pipeline([("scaler", StandardScaler()), ("clf", clf_cv)])
        else:
            cv_pipeline = clf_cv
        scores_cv = cross_val_score(cv_pipeline, X, y, cv=5)
        st.plotly_chart(graf_cv(scores_cv), use_container_width=True)

        # GrÃ¡ficas de desempeÃ±o
        col_a, col_b = st.columns(2)
        with col_a:
            st.subheader("ğŸ—‚ï¸ Matriz de ConfusiÃ³n")
            st.plotly_chart(
                graf_confusion(y_test, y_pred, target_names), use_container_width=True
            )
        with col_b:
            st.subheader("ğŸ“ˆ Curvas ROC")
            fig_roc = graf_roc(modelo, X_test, y_test, target_names)
            if fig_roc:
                st.plotly_chart(fig_roc, use_container_width=True)
            else:
                st.info("Este clasificador no soporta probabilidades para ROC.")

        # Reporte de clasificaciÃ³n
        st.subheader("ğŸ“„ Reporte de ClasificaciÃ³n")
        report_dict = classification_report(
            y_test, y_pred, target_names=target_names, output_dict=True
        )
        df_report = pd.DataFrame(report_dict).transpose()
        st.dataframe(df_report.style.format("{:.2f}"), use_container_width=True)

        # Importancia de caracterÃ­sticas
        fig_imp = graf_importancia(modelo, feature_names, clasificador_nombre)
        if fig_imp:
            st.subheader("ğŸ” Importancia de CaracterÃ­sticas")
            st.plotly_chart(fig_imp, use_container_width=True)

        # Ãrbol de decisiÃ³n: visualizaciÃ³n del Ã¡rbol
        if clasificador_nombre == "Ãrbol de DecisiÃ³n":
            with st.expander("ğŸŒ³ Ver estructura del Ã¡rbol de decisiÃ³n"):
                fig_tree, ax = plt.subplots(figsize=(16, 6))
                plot_tree(
                    modelo,
                    feature_names=feature_names,
                    class_names=target_names,
                    filled=True,
                    rounded=True,
                    fontsize=9,
                    ax=ax,
                )
                st.pyplot(fig_tree)
                plt.close(fig_tree)

                rules = export_text(
                    modelo, feature_names=list(feature_names)
                )
                st.code(rules, language="text")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PESTAÃ‘A 3: PREDICCIÃ“N
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with tab_prediccion:
        st.header("ğŸ”® Interfaz de PredicciÃ³n")
        st.markdown(
            "Introduce los valores de las caracterÃ­sticas para obtener la predicciÃ³n "
            "del clasificador entrenado y la probabilidad estimada para cada clase."
        )

        # Reentrenar con todos los datos para predecir
        X_full = df[feature_names].values
        if escalar:
            scaler_full = StandardScaler()
            X_full_scaled = scaler_full.fit_transform(X_full)
        else:
            X_full_scaled = X_full
            scaler_full = None

        modelo_full = crear_clasificador(clasificador_nombre, params)
        modelo_full.fit(X_full_scaled, iris.target)

        st.subheader("Introduce las medidas de la flor")
        stats = df[feature_names].describe()

        col1, col2 = st.columns(2)
        with col1:
            sepal_length = st.number_input(
                feature_names[0],
                min_value=float(stats.loc["min", feature_names[0]]),
                max_value=float(stats.loc["max", feature_names[0]]),
                value=float(stats.loc["mean", feature_names[0]]),
                step=0.1,
                format="%.1f",
            )
            sepal_width = st.number_input(
                feature_names[1],
                min_value=float(stats.loc["min", feature_names[1]]),
                max_value=float(stats.loc["max", feature_names[1]]),
                value=float(stats.loc["mean", feature_names[1]]),
                step=0.1,
                format="%.1f",
            )
        with col2:
            petal_length = st.number_input(
                feature_names[2],
                min_value=float(stats.loc["min", feature_names[2]]),
                max_value=float(stats.loc["max", feature_names[2]]),
                value=float(stats.loc["mean", feature_names[2]]),
                step=0.1,
                format="%.1f",
            )
            petal_width = st.number_input(
                feature_names[3],
                min_value=float(stats.loc["min", feature_names[3]]),
                max_value=float(stats.loc["max", feature_names[3]]),
                value=float(stats.loc["mean", feature_names[3]]),
                step=0.1,
                format="%.1f",
            )

        if st.button("ğŸŒ¸ Predecir especie", type="primary"):
            entrada = np.array([[sepal_length, sepal_width, petal_length, petal_width]])
            if scaler_full:
                entrada_scaled = scaler_full.transform(entrada)
            else:
                entrada_scaled = entrada

            pred_idx = modelo_full.predict(entrada_scaled)[0]
            pred_clase = target_names[pred_idx]

            st.success(f"### Especie predicha: **{pred_clase}** ğŸŒ¸")

            if hasattr(modelo_full, "predict_proba"):
                probas = modelo_full.predict_proba(entrada_scaled)[0]
                df_prob = pd.DataFrame(
                    {"Especie": target_names, "Probabilidad": probas}
                )
                fig_prob = px.bar(
                    df_prob,
                    x="Especie",
                    y="Probabilidad",
                    color="Especie",
                    title="Probabilidad estimada por clase",
                    color_discrete_sequence=px.colors.qualitative.Set2,
                    text=[f"{p:.1%}" for p in probas],
                )
                fig_prob.update_traces(textposition="outside")
                fig_prob.update_layout(
                    yaxis=dict(range=[0, 1.1]),
                    showlegend=False,
                )
                st.plotly_chart(fig_prob, use_container_width=True)

            # Mostrar posiciÃ³n de la muestra en el espacio de caracterÃ­sticas
            st.subheader("ğŸ“ PosiciÃ³n de la muestra en el dataset")
            df_plot = df.copy()
            fig_pos = px.scatter(
                df_plot,
                x=feature_names[2],
                y=feature_names[3],
                color="especie",
                title="Muestra ingresada vs dataset (pÃ©talo largo vs ancho)",
                color_discrete_sequence=px.colors.qualitative.Set2,
                opacity=0.6,
            )
            fig_pos.add_trace(
                go.Scatter(
                    x=[petal_length],
                    y=[petal_width],
                    mode="markers",
                    marker=dict(size=16, color="red", symbol="star"),
                    name=f"Tu muestra â†’ {pred_clase}",
                )
            )
            st.plotly_chart(fig_pos, use_container_width=True)


if __name__ == "__main__":
    main()
